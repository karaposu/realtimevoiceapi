# VoxTerm ğŸ™ï¸

**A lightweight, non-blocking terminal UI framework for real-time voice applications**

VoxTerm provides a rich terminal interface for voice-enabled applications without compromising real-time performance. It's designed as a thin UI layer that works seamlessly with voice engines like `realtimevoiceapi.VoiceEngine`, handling display and user interaction while your voice engine handles the actual audio processing.

## ğŸš€ Key Features

- **Zero-latency UI**: Event-driven architecture that never blocks audio streams
- **Voice Engine Agnostic**: Works with any voice API (OpenAI, Google, Azure, custom)
- **Flexible Input Modes**: Push-to-talk, always-on, turn-based, or text-only
- **Real-time Display**: Live transcriptions, status updates, and audio levels
- **Non-intrusive**: Runs in separate thread, preserving voice engine's real-time capabilities
- **Minimal Dependencies**: Pure Python with optional enhancements

## ğŸ¯ What VoxTerm Is (and Isn't)

### âœ… VoxTerm IS:
- A **terminal UI framework** for voice applications
- A **display layer** for conversations, status, and controls  
- An **input coordinator** for keyboard, commands, and mode switching
- A **non-blocking event system** that preserves real-time performance

### âŒ VoxTerm is NOT:
- A voice API or speech recognition system
- An audio processing library
- A VAD implementation (uses your voice engine's VAD)
- A WebSocket/networking layer

## ğŸ—ï¸ Architecture

VoxTerm is designed as a thin, event-driven layer that sits **alongside** your voice engine, not in front of it:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Voice    â”‚ <-----> â”‚   Voice API      â”‚
â”‚   Engine        â”‚         â”‚ (OpenAI, etc)    â”‚
â”‚ (Audio Process) â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                
         â”‚ Events (text, audio, state)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    VoxTerm      â”‚ â† Terminal UI (separate thread)
â”‚  (UI Display)   â”‚ â† Never blocks audio pipeline
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
voxterm/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src/
â”‚   â””â”€â”€ voxterm/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ core/                 # Core abstractions
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ terminal.py       # Main VoxTerminal class
â”‚       â”‚   â”œâ”€â”€ events.py         # Event system (non-blocking)
â”‚       â”‚   â””â”€â”€ interfaces.py     # API contracts
â”‚       â”‚
â”‚       â”œâ”€â”€ display/              # Terminal rendering (separate thread)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ renderer.py       # Terminal display engine
â”‚       â”‚   â”œâ”€â”€ components.py     # UI components (status bar, etc)
â”‚       â”‚   â”œâ”€â”€ formatters.py     # Message formatting
â”‚       â”‚   â””â”€â”€ themes.py         # Color schemes
â”‚       â”‚
â”‚       â”œâ”€â”€ input/                # Input handling
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ keyboard.py       # Keyboard event handling
â”‚       â”‚   â”œâ”€â”€ commands.py       # Command parsing
â”‚       â”‚   â””â”€â”€ modes.py          # Input mode controllers
â”‚       â”‚
â”‚       â”œâ”€â”€ integration/          # Voice engine integrations
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py           # Base integration class
â”‚       â”‚   â””â”€â”€ voice_engine.py   # VoiceEngine integration
â”‚       â”‚
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ async_helpers.py  # Async utilities
â”‚           â””â”€â”€ terminal.py       # Terminal utilities
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ simple_chat.py            # Basic usage
â”‚   â”œâ”€â”€ voice_engine_chat.py      # With VoiceEngine
â”‚   â””â”€â”€ custom_integration.py     # Custom voice API
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_display.py
    â”œâ”€â”€ test_events.py
    â””â”€â”€ test_integration.py
```

## ğŸ¯ Implementation Goals

### 1. **Zero-Blocking Architecture**
- UI runs in separate thread/process
- Event-driven communication via queues
- No synchronous calls in audio path
- Display updates are fire-and-forget

### 2. **Voice Engine Integration First**
- Built specifically for `realtimevoiceapi.VoiceEngine`
- Uses VoiceEngine's VAD, audio handling, and networking
- VoxTerm only handles display and keyboard input
- Clean integration via callbacks and events

### 3. **Minimal Overhead**
- < 5ms latency for event propagation
- < 1% CPU usage during idle
- Memory-efficient message buffering
- No audio processing or copying

### 4. **Developer Experience**
- Simple 5-line integration
- Sensible defaults
- Progressive enhancement
- Clear extension points

## ğŸš€ Quick Start

### Basic Usage with VoiceEngine

```python
from voxterm import VoxTerminal
from realtimevoiceapi import VoiceEngine

# Create your voice engine
engine = VoiceEngine(api_key="...")

# Create terminal UI
terminal = VoxTerminal(
    title="AI Voice Chat",
    mode="push_to_talk"  # or "always_on", "turn_based", "text"
)

# Connect VoiceEngine to VoxTerm (non-blocking)
terminal.bind_voice_engine(engine)

# Run the UI (starts in separate thread)
terminal.run()

# Your voice engine continues to run at full speed!
await engine.connect()
```

### Manual Integration

```python
# VoxTerm exposes simple callbacks
terminal.on_user_input = lambda text: engine.send_text(text)
terminal.on_push_to_talk_start = lambda: engine.start_listening()
terminal.on_push_to_talk_end = lambda: engine.stop_listening()
terminal.on_interrupt = lambda: engine.interrupt()

# Feed display updates from your engine
engine.on_text_response = terminal.display_ai_text
engine.on_user_transcript = terminal.display_user_text
engine.on_state_change = terminal.update_status
```

## ğŸ”§ Configuration

VoxTerm delegates all audio/VAD configuration to your voice engine:

```python
# VoxTerm configuration (UI only)
terminal_config = {
    "theme": "dark",
    "show_timestamps": True,
    "show_audio_levels": True,
    "key_bindings": {
        "push_to_talk": "space",
        "interrupt": "escape",
        "mute": "m",
        "quit": "q"
    }
}

# Voice configuration (handled by your engine)
engine_config = {
    "vad_threshold": 0.5,      # VoxTerm doesn't touch this
    "sample_rate": 24000,      # VoxTerm doesn't care
    "voice": "alloy"           # VoxTerm just displays it
}
```

## ğŸ¨ UI Components

### Status Bar
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¢ Connected â”‚ Mode: Push-to-Talk â”‚ Mic: ON â”‚ âš¡ 45ms â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conversation Display
```
[09:34:12] You: What's the weather like today?
           
[09:34:13] AI: I don't have access to real-time weather data,
               but I'd be happy to help you find weather 
               information for your area.

[09:34:18] You: [Listening...]
```

### Control Hints
```
[SPACE] Hold to talk â”‚ [M] Mute â”‚ [L] Toggle logs â”‚ [Q] Quit
```

## ğŸ”Œ Integration Examples

### OpenAI Realtime
```python
from voxterm import VoxTerminal
from realtimevoiceapi import VoiceEngine

terminal = VoxTerminal()
engine = VoiceEngine(api_key="...")
terminal.bind_voice_engine(engine)
terminal.run()
```

### Google Speech
```python
from voxterm import VoxTerminal, BaseIntegration

class GoogleSpeechIntegration(BaseIntegration):
    def connect_to_terminal(self, terminal, speech_client):
        # Wire up callbacks
        pass

terminal = VoxTerminal()
integration = GoogleSpeechIntegration()
integration.connect_to_terminal(terminal, google_client)
terminal.run()
```

## ğŸƒ Performance

VoxTerm is designed to have **zero impact** on real-time voice processing:

- **Display updates**: Async, non-blocking queue (< 1ms)
- **Keyboard events**: Separate thread with event queue
- **Memory usage**: < 10MB for typical conversation
- **CPU usage**: < 1% during conversation
- **Latency added**: 0ms to voice pipeline

## ğŸ› ï¸ Advanced Usage

### Custom Display Components
```python
from voxterm.display import Component

class TokenCounter(Component):
    def render(self, state):
        return f"Tokens: {state.token_count}"

terminal.add_component(TokenCounter(), position="status_right")
```

### Custom Input Modes
```python
from voxterm.input import InputMode

class DoubleTapMode(InputMode):
    """Double-tap space to toggle recording"""
    def handle_key(self, key):
        # Implementation
        pass

terminal.add_input_mode("double_tap", DoubleTapMode())
```

## ğŸ“ Design Principles

1. **Never Block Audio**: UI updates are always async and queued
2. **Delegate to Voice Engine**: VoxTerm doesn't implement VAD, audio processing, or networking
3. **Event-Driven**: Loose coupling via events, not direct calls
4. **Thread-Safe**: UI thread is isolated from audio processing
5. **Extensible**: Easy to add new modes, themes, and integrations

## ğŸš§ Roadmap

- [ ] Rich TUI mode with `textual`
- [ ] Web terminal via `xterm.js`
- [ ] Recording/playback controls
- [ ] Multi-language UI support
- [ ] Plugin system for custom widgets

## ğŸ“„ License

MIT License - Use freely in your voice applications!

---

**Remember**: VoxTerm is just the UI layer. It's designed to make your voice application look good in the terminal without slowing down your real-time audio processing. Your voice engine does the heavy lifting - VoxTerm just makes it pretty! ğŸ¨